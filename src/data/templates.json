[
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Holodeck Husky Braitenberg experiment with SpiNNaker",
    "thumbnail": "ExDSpiNNakerExample.jpg",
    "description": "This is a SpiNNaker compatible version of the Braitenberg Brain Husky Experiment in the holodeck.",
    "tags": "holodeck Husky braitenberg spinnaker robotics",
    "timeout": "6000",
    "configuration": [
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDSpiNNakerExample.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "virtual_room/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "1.0",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "milestone2_spinnaker_python_tf.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Tutorial baseball experiment - Exercise",
    "thumbnail": "ExDTutorialBaseball.jpg",
    "description": "This guided experiment will walk you through all the features of the Neurorobotics Platform. Launch it and follow the instructions provided in the jupyter notebook located in the Experiments/tutorial_baseball_exercise folder.",
    "tags": "icub robotics tutorial exercise baseball tutorial",
    "timeout": "86400",
    "configuration": [
      {
        "src": "ExDTutorialBaseball.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDTutorialBaseball.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "empty_world/empty_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.624",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "2.29524196972"
      }
    },
    "bibiConf": {
      "src": "tutorial_baseball.bibi"
    },
    "experimentControl": {
      "stateMachine": {
        "type": "SMACHStateMachine",
        "id": "BallThrowingMachine",
        "src": "throw_ball.exd"
      }
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "2.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Template HoLLie arm in empty environment",
    "thumbnail": "ExDTemplateManipulation.jpg",
    "description": "Loads a custom build robot model of a table and one of the HoLLie robot arms with the hand fixed to it.",
    "tags": "template hollie robotics arm empty",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDTemplateManipulation.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDTemplateManipulation.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "empty_world/empty_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.04",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "template_manipulation.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "My Leg 01",
    "thumbnail": "ExDTutorialBaseball.jpg",
    "description": "first custom setup with leg mechanics",
    "tags": "legs tryout",
    "timeout": "86400.0",
    "configuration": [
      {
        "src": "ExDTutorialBaseball.3ds"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDTutorialBaseball.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "empty_world/empty_world.sdf",
      "robotPose": {
        "theta": "0.0",
        "ux": "0.0",
        "uy": "0.0",
        "uz": "0.0",
        "x": "0.0",
        "y": "0.0",
        "z": "0.0"
      }
    },
    "bibiConf": {
      "src": "bibi_configuration.bibi"
    },
    "experimentControl": {
      "stateMachine": {
        "id": "BallThrowingMachine",
        "src": "BallThrowingMachine.exd",
        "type": "SMACHStateMachine"
      }
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "-0.5",
        "y": "-3.5",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0.0",
        "y": "0.0",
        "z": "2.0"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "HoLLiE hand motion with CPG in holodeck",
    "thumbnail": "ExDManipulation.jpg",
    "description": "This experiment shows a basic implementation of CPG driven motion control for a five-finger robotic hand. The transfer functions implement a simple muscle model.",
    "tags": "hollie hand cpg holodeck",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDManipulation.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDManipulation.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "virtual_room/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.025",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "manipulation.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "-1.05711",
        "y": "2.06968",
        "z": "2.08684"
      },
      "cameraLookAt": {
        "x": "0.0",
        "y": "0.231642",
        "z": "1.199802"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Template Husky in empty environment",
    "thumbnail": "ExDTemplateHusky.jpg",
    "description": "This experiment loads the Husky robot in an empty world, with an idle brain and basic transfer functions. You are free to edit it.",
    "tags": "template husky robotics empty",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDTemplateHusky.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDTemplateHusky.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "empty_world/empty_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.5",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "0.0"
      }
    },
    "bibiConf": {
      "src": "template_husky.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Holodeck Husky Braitenberg experiment with automatically switching screens",
    "thumbnail": "ScreenSwitchingHuskyExperiment.jpg",
    "description": "This experiment is similar to the Husky Braitenberg one in the Holodeck (Husky robot detecting red colour and driving towards it). In this experiment the right screen is turned red automatically after 20 seconds of simulation time. Also, the robot reaching a red screen triggers on the opposite screen. This is to demonstrate how, using the SMACH state machine script, the user can automate the experiment events.",
    "tags": "husky robotics braitenberg screen holodeck",
    "timeout": "840",
    "configuration": [
      {
        "src": "ScreenSwitchingHuskyExperiment.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ScreenSwitchingHuskyExperiment.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "virtual_room/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.5",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "milestone2.bibi"
    },
    "experimentControl": {
      "stateMachine": {
        "type": "SMACHStateMachine",
        "id": "HuskyAwareScreenControlling",
        "src": "screen_switching_husky_aware_compatible.exd"
      }
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "5.056825994369357",
        "y": "-1.0210998541555323",
        "z": "2.697598759953974"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.49999"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Husky with neuronal red detection",
    "thumbnail": "NeuronalRedDetection_Husky.jpg",
    "description": "This experiment loads the Husky robot from Clearpath Robotics and the virtual room environment. If the user starts the experiment, the Braitenberg vehicle network is executed and the robot will turn around itself in place, until the camera detects a red color. The color detection is done with a neuronal image recognition. Then, the robot will move towards the colored object. In this experiment, the user can interact and change the color of both screens by clicking on them with the right mouse button.",
    "tags": "husky robotics visual virtualroom braitenberg neuronal",
    "timeout": "1680",
    "configuration": [
      {
        "src": "ExDXMLExample.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDXMLExample.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "virtual_room_lausanne/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.5",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "neuronalRedDetection.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "2.1504202465717563",
        "y": "1.2381462778435453",
        "z": "1.3380507195673994"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.49999"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ExDConfFile.xsd",
    "name": "iCub robot with Dynamic Vision Sensor (DVS) demo",
    "thumbnail": "ExDDvsIcub.jpg",
    "description": "This experiment contains an iCub robot equipped with one simulated Dynamic Vision Sensors and another iCub robot that is waving periodically its left or right hand. The iCub with a DVS tries to replicate the hand motion of the other one.",
    "tags": "icub visual dvs vision robotics empty",
    "timeout": "180",
    "configuration": [
      {
        "src": "ExDDvsIcub.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDDvsIcub.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "tracking_world/tracking_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "-0.5",
        "z": "0.63",
        "roll": "0.0",
        "pitch": "0.0",
        "yaw": "-1.57079632679"
      }
    },
    "bibiConf": {
      "src": "DVSIcub.bibi"
    },
    "experimentControl": {
      "stateMachine": {
        "type": "SMACHStateMachine",
        "id": "IcubBehaviorSwitch",
        "src": "icub_behavior_switch.exd"
      }
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "2.5",
        "y": "2.5",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Holodeck Force based joint control",
    "thumbnail": "ExDManipulationForce.jpg",
    "description": "The experiment shows a simple example of force based spiking interface for a Schunk SVH robotic hand. Two joints of the index finger are being controlled by two motor neurons (antagonist and synergist) to reach a desired position, which is adjustable in the transfer function. A simple muscle model converts activation dynamics to joint efforts and applies them in a physics simulator. The rest of the 8 joints (2 for each finger) are maintaining zero positions with traditional PID controllers and do not move at all. The experiment demonstrates one of the possible mechanisms for implementing force based control using existing Gazebo/ROS NRP platform architecture, opening the path to more complex muscle model simulations in the future.",
    "tags": "holodeck force based joint control robotics",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDManipulationForce.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDManipulationForce.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "virtual_room/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.025",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "manipulation_force.bibi"
    },
    "experimentControl": {
      "stateMachine": {
        "type": "SMACHStateMachine",
        "id": "IndexFingerForceControl",
        "src": "manipulation_arm_robot_force.exd"
      }
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "-1.05711",
        "y": "2.06968",
        "z": "2.08684"
      },
      "cameraLookAt": {
        "x": "0.0",
        "y": "0.231642",
        "z": "1.199802"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "LAURON V Braitenberg experiment in the SpaceBotCup 2013 arena",
    "thumbnail": "ExDBraitenbergLauronSBC.jpg",
    "description": "This experiment loads the six-legged walking robot LAURON V (developed at FZI) and the arena from the SpaceBotCup 2013. If the user starts the experiment, the Braitenberg vehicle network is executed and the robot will turn around itself in place, until the camera detects a red color. Then, the robot will move towards the colored object. In this experiment, the user can interact and change the color of both screens by clicking on them with the right mouse button.",
    "tags": "lauron braitenberg spacebotcup robotics",
    "timeout": "840",
    "configuration": [
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDBraitenbergLauronSBC.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "spacebotcup_world/spacebotcup_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "1.25",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "0.0"
      }
    },
    "bibiConf": {
      "src": "braitenberg_lauron.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "-2.95",
        "y": "-17.30",
        "z": "3"
      },
      "cameraLookAt": {
        "x": "10",
        "y": "12",
        "z": "-5"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Docked Mouse v2 experiment",
    "thumbnail": "ExDDockedMouse.jpg",
    "description": "This experiment loads the Mouse in an empty world, with an idle brain and the docked walking controller.",
    "tags": "mouse biological old empty",
    "timeout": "840",
    "configuration": [
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDDockedMouse.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "empty_world/empty_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.8",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "2.29524196972"
      }
    },
    "bibiConf": {
      "src": "docked_mouse_v2.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Tutorial baseball experiment - Solution",
    "thumbnail": "ExDTutorialBaseball.jpg",
    "description": "This guided experiment will walk you through all the features of the Neurorobotics Platform. Launch it and follow the instructions provided in the jupyter notebook located in the Experiments/tutorial_baseball_exercise/ folder.",
    "tags": "icub robotics tutorial solution baseball",
    "timeout": "86400",
    "configuration": [
      {
        "src": "ExDTutorialBaseball.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDTutorialBaseball.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "empty_world/empty_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.624",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "2.29524196972"
      }
    },
    "bibiConf": {
      "src": "tutorial_baseball.bibi"
    },
    "experimentControl": {
      "stateMachine": {
        "type": "SMACHStateMachine",
        "id": "BallThrowingMachine",
        "src": "throw_ball.exd"
      }
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "2.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "2 DOF NST Myorobotics Arm for WP4 Cerebellum Experiment",
    "thumbnail": "Myo_NST.jpg",
    "description": "Loads the 2 DOF Myorobotics Arm into the Holodeck. Muscles can be controlled via ROS messages.",
    "timeout": "1000000000",
    "configuration": [
      {
        "src": "holodeck.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "holodeck.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "cdp1_world/cdp1_world_holodeck.sdf",
      "robotPose": {
        "x": "-1",
        "y": "-4.0",
        "z": "0.1",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "0.0"
      }
    },
    "bibiConf": {
      "src": "Myo_NST.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "1.650596943953666",
        "y": "-1.3037450422457924",
        "z": "1.3963657402299325"
      },
      "cameraLookAt": {
        "x": "1.51587",
        "y": "-1.0442",
        "z": "1.33757"
      }
    },
    "physicsEngine": "opensim",
    "gzbridgesettings": {
      "pose_update_delta_translation": "1.e-12",
      "pose_update_delta_rotation": "1.e-12",
      "pose_update_early_threshold": "0.02"
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Holodeck iCub Visual Tracking experiment",
    "thumbnail": "ExDVisualTrackingICub.jpg",
    "description": "In this experiment the iCub robot performs a Visual Tracking task in the Holodeck.",
    "tags": "icub robotics visual holodeck",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDVisualTrackingICub.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDVisualTrackingICub.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "virtual_room/virtual_room_tracking_icub.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.644",
        "roll": "0.0",
        "pitch": "0.0",
        "yaw": "-1.570796"
      }
    },
    "bibiConf": {
      "src": "visual_tracking_icub.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "2.1504202465717563",
        "y": "1.2381462778435453",
        "z": "1.3380507195673994"
      },
      "cameraLookAt": {
        "x": "0.0",
        "y": "1.48",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Empty Template MMM experiment",
    "thumbnail": "ExDTemplateMMM.png",
    "description": "This experiment loads the MMM model in an empty world, with an idle brain and basic transfer functions. You are free to edit it.",
    "tags": "template mmm empty",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDTemplateMMM.json"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDTemplateMMM.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "empty_world/empty_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.556",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "2.29524196972"
      }
    },
    "bibiConf": {
      "src": "template_mmm.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "2",
        "y": "0",
        "z": "1"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.1"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Tutorial - TensorFlow Husky Braitenberg Experiment",
    "thumbnail": "TensorFlowTutorial.jpg",
    "description": "This experiment was presented as a tutorial at the CodeJam 2017 event. It demonstrates using TensorFlow within the NRP for semantic object segmentation/detection in conjunction with the spiking neuron Braitenberg brain for object level interaction. Find more information in the README file in Experiments/tutorial_tensorflow_husky.",
    "tags": "husky tutorial robotics tensorflow braitenberg holodeck",
    "timeout": "86400",
    "configuration": [
      {
        "src": "TensorFlowTutorial.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "TensorFlowTutorial.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "codejam_2017_tensorflow_world/tensorflow_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.5",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "TensorFlowTutorial.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "3.25",
        "y": "4.75",
        "z": "4.25"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.5"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Holodeck iCub mockup experiment with Retina embedding",
    "thumbnail": "ExDRetinaICubMockup.png",
    "description": "In this experiment the iCub robot sends visual input to a retina model.",
    "tags": "icub retina robotics holodeck",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDRetinaICubMockup.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDRetinaICubMockup.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "virtual_room/virtual_room_tracking_icub.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "1.5",
        "z": "0.644",
        "roll": "0.0",
        "pitch": "0.0",
        "yaw": "-1.570796"
      }
    },
    "bibiConf": {
      "src": "visual_tracking_icub_retina_mockup.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "1.4",
        "y": "2.15",
        "z": "1.0"
      },
      "cameraLookAt": {
        "x": "0.0",
        "y": "1.48",
        "z": "0.8"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Holodeck Husky Braitenberg experiment",
    "thumbnail": "ExDXMLExample.jpg",
    "description": "This experiment loads the Husky robot from Clearpath Robotics in the Holodeck environment. If the user starts the experiment, the Braitenberg vehicle network is executed and the robot will turn around itself in place, until the camera detects a red color. Then, the robot will move towards the colored object. In this experiment, the user can interact and change the color of both screens by clicking on them with the right mouse button.",
    "tags": "husky robotics holodeck braitenberg",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDXMLExample.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDXMLExample.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "virtual_room/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.5",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "milestone2_python_tf.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "5.056825994369357",
        "y": "-1.0210998541555323",
        "z": "2.697598759953974"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.49999"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Template Lauron in empty environment",
    "thumbnail": "ExDTemplateLauron.jpg",
    "description": "This experiment loads the Lauron robot in an empty world, with an idle brain and basic transfer functions. You are free to edit it.",
    "tags": "lauron template docked robotics empty",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDTemplateLauron.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDTemplateLauron.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "empty_world/empty_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "1",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "0.0"
      }
    },
    "bibiConf": {
      "src": "template_lauron.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "iCub Visual Tracking experiment",
    "thumbnail": "ExDVisualTrackingICub.jpg",
    "description": "In this experiment the iCub robot performs a Visual Tracking task in the virtual room environment.",
    "tags": "icub robotics visual virtualroom",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDVisualTrackingICub.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDVisualTrackingICub.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "virtual_room_lausanne/virtual_room_tracking_icub.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.644",
        "roll": "0.0",
        "pitch": "0.0",
        "yaw": "-1.570796"
      }
    },
    "bibiConf": {
      "src": "visual_tracking_icub.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "2.1504202465717563",
        "y": "1.2381462778435453",
        "z": "1.3380507195673994"
      },
      "cameraLookAt": {
        "x": "0.0",
        "y": "1.48",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Mouse demo experiment in biology lab",
    "thumbnail": "ExDMouseLabExample.jpg",
    "description": "This demo shows how to manipulate the environment from a state machine. Objects are created during the experiment and change the behaviour of the mouse.",
    "tags": "mouse demo braitenberg biological holodeck",
    "timeout": "210",
    "configuration": [
      {
        "src": "ExDMouseLabExample.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDMouseLabExample.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "biologylab_world/biologylab.sdf",
      "robotPose": {
        "x": "-1.0",
        "y": "-2.0",
        "z": "1.135",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "1.58692500941"
      }
    },
    "visualModel": {
      "src": "mouse_v2_model/meshes/mouse_v2_model_animated.dae",
      "scale": "0.01",
      "visualPose": {
        "x": "-0.895",
        "y": "-1.9975",
        "z": "1.115",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "1.5708"
      }
    },
    "bibiConf": {
      "src": "ExDMouseLabExample.bibi"
    },
    "experimentControl": {
      "stateMachine": {
        "type": "SMACHStateMachine",
        "id": "SMACH_Example",
        "src": "mouse_smach_state.exd"
      }
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "-1.02",
        "y": "-1.7",
        "z": "1.35"
      },
      "cameraLookAt": {
        "x": "-0.3",
        "y": "-2.1",
        "z": "1.15"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Husky with neuronal red detection in holodeck",
    "thumbnail": "NeuronalRedDetection_Husky.jpg",
    "description": "This experiment loads the Husky robot from Clearpath Robotics and the virtual room environment. If the user starts the experiment, the Braitenberg vehicle network is executed and the robot will turn around itself in place, until the camera detects a red color. The color detection is done with a neuronal image recognition. Then, the robot will move towards the colored object. In this experiment, the user can interact and change the color of both screens by clicking on them with the right mouse button.",
    "tags": "husky holodeck braitenberg neural detection",
    "timeout": "1680",
    "configuration": [
      {
        "src": "NeuronalRedDetection_Husky.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "NeuronalRedDetection_Husky.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "virtual_room/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.5",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "neuronalRedDetection.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "5.056825994369357",
        "y": "-1.0210998541555323",
        "z": "2.697598759953974"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.49999"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Mouse Braitenberg experiment",
    "thumbnail": "ExDBraitenbergMouse.jpg",
    "description": "This experiment loads the soft-skin mouse model in a virtual lab environment. If the user starts the experiment, the mouse will stay still, until its eyes detect a red color on one screen. Then, the mouse will move the head towards the colored object. In this experiment, the user can interact and change the color of both screens by clicking on them with the right mouse button.",
    "tags": "mouse biological visual braitenberg empty",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDBraitenbergMouse.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDBraitenbergMouse.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "mouse_ymaze_world/mouse_lab.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "-1.5",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "0.0"
      }
    },
    "visualModel": {
      "src": "mouse_v1_model/meshes/mouse_v1_model_animated.dae",
      "visualPose": {
        "x": "0.0",
        "y": "5.0",
        "z": "-2.62",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "0.0"
      }
    },
    "bibiConf": {
      "src": "braitenberg_mouse.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "15.0",
        "y": "4.0",
        "z": "12.0"
      },
      "cameraLookAt": {
        "x": "0.0",
        "y": "-7.0",
        "z": "-3.0"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "CDP1 Mouse experiment - Tactile feedback",
    "thumbnail": "ExDMouseCDP1.jpg",
    "description": "CDP-1 mouse experiment MVP with tactile feedback",
    "timeout": "1000000000",
    "configuration": [
      {
        "src": "ExDMouseCDP1.ini"
      },
      {
        "src": "MouseCDP1NeuronCoords.json"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "cdp1_world/cdp1_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.0",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "0.0"
      }
    },
    "bibiConf": {
      "src": "MouseCDP1.bibi"
    },
    "experimentControl": {
      "stateMachine": {
        "type": "SMACHStateMachine",
        "id": "MouseCDP1Control_SMACH",
        "src": "MouseCDP1Control.exd"
      }
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "0.20881767737668355",
        "y": "-0.26",
        "z": "0.07452707557551946"
      },
      "cameraLookAt": {
        "x": "-0.527092211",
        "y": "0.839239426",
        "z": "-0.133607597"
      }
    },
    "physicsEngine": "opensim",
    "gzbridgesettings": {
      "pose_update_delta_translation": "1.e-12",
      "pose_update_delta_rotation": "1.e-12",
      "pose_update_early_threshold": "0.02"
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Holodeck hollie Arm Reinforcement-Learning for target reaching",
    "thumbnail": "ExDManipulationRL.jpg",
    "description": "A simple learning experiment with a Gaussian-shaped input population encoding the current position of a single arm axis which is connected via a dopamine regulated STDP synapse to two motor neurons. The absolute error between current joint and target angle determines the dopamine level. Random motor babbling helps the learning mechanism to explore the joint space and to correlate input and output layer.",
    "tags": "robotics hollie hand finger sdtp holodeck reinforcement learning",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDManipulationRL.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDManipulationRL.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "virtual_room/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.025",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "manipulation_reinforcement_learning.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "-1.05711",
        "y": "2.06968",
        "z": "2.08684"
      },
      "cameraLookAt": {
        "x": "0.0",
        "y": "0.231642",
        "z": "1.199802"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "New experiment",
    "thumbnail": "TemplateNew.jpg",
    "description": "This new experiment is based on the models that you have selected. You are free to edit the description.",
    "timeout": "840",
    "configuration": [
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "TemplateNew.ini"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "empty_world/empty_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.5",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "0.0"
      }
    },
    "bibiConf": {
      "src": "TemplateNew.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Holodeck template iCub",
    "thumbnail": "ExDTemplateICubHolodeck.jpg",
    "description": "This experiment loads the iCub robot in the holodeck, with an idle brain and basic transfer functions. You are free to edit it.",
    "tags": "icub robotics holodeck template",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDTemplateICubHolodeck.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDTemplateICubHolodeck.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "empty_virtuallab/empty_virtuallab.sdf",
      "robotPose": {
        "x": "1.929",
        "y": "0.286",
        "z": "0.949",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "2.29524196972"
      }
    },
    "bibiConf": {
      "src": "template_icub.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.82578462912139",
        "y": "-1.3670388948566252",
        "z": "1.6209022560153437"
      },
      "cameraLookAt": {
        "x": "1.929",
        "y": "0.286",
        "z": "1.0"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "WP2 featuring experiment",
    "thumbnail": "Images/Conjoint.jpg",
    "description": "This experiment demonstrates the flexibility of the WP2 visual system by running many of its model all together in a meaningful task. The robot has to follow the visual stimulus with its eyes, and identify the target after the square flanker is segmented out.",
    "timeout": "100000",
    "configuration": {
      "src": "Conjoint.3ds"
    },
    "maturity": "production",
    "environmentModel": {
      "src": "crowding_virtuallab/moving_square_virtuallab.sdf",
      "robotPose": {
        "x": "-8.59",
        "y": "-1.435",
        "z": "1.582",
        "ux": "0.0",
        "uy": "0.0",
        "uz": "0.0",
        "theta": "1.0"
      }
    },
    "bibiConf": {
      "src": "Conjoint.bibi"
    },
    "experimentControl": {
      "stateMachine": {
        "type": "SMACHStateMachine",
        "id": "StimulusDisplayMachine",
        "src": "StateMachines/displayStimuli.exd"
      }
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "2.1",
        "y": "1.2",
        "z": "1.3"
      },
      "cameraLookAt": {
        "x": "0.0",
        "y": "1.5",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Template iCub in empty environment",
    "thumbnail": "ExDTemplateICub.jpg",
    "description": "This experiment loads the iCub robot in an empty world, with an idle brain and basic transfer functions. You are free to edit it.",
    "tags": "icub robotics template empty",
    "timeout": "840",
    "configuration": [
      {
        "src": "config/ExDTemplateICub.ini"
      },
      {
        "src": "config/brainvisualizer.json"
      },
      {
        "src": "config/ExDTemplateICub.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "empty_world/empty_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.8",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "2.29524196972"
      }
    },
    "bibiConf": {
      "src": "config/template_icub.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "2.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Husky labyrinth demo experiment in the SpaceBotCup 2013 arena",
    "thumbnail": "ExDDemoHuskySBC.jpg",
    "description": "In this experiment the robot will find his path in a labyrinth by following red lights.",
    "tags": "husky robotics maze labyrinth spacebotcup demo",
    "timeout": "210",
    "configuration": [
      {
        "src": "ExDDemoHuskySBC.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDDemoHuskySBC.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "spacebotcup_world_labyrinth/spacebotcup_world.sdf",
      "robotPose": {
        "x": "1.33815",
        "y": "-2.07915",
        "z": "1.08401",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "0.0"
      }
    },
    "bibiConf": {
      "src": "milestone2.bibi"
    },
    "experimentControl": {
      "stateMachine": {
        "type": "SMACHStateMachine",
        "id": "HuskyAwareLabScreenControlling",
        "src": "demo_husky_switch_screen.exd"
      }
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "11.090271978222098",
        "y": "-0.5979270020610832",
        "z": "9.025477327075356"
      },
      "cameraLookAt": {
        "x": "1.33815",
        "y": "-2.07915",
        "z": "1.08401"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ExDConfFile.xsd",
    "name": "Mouse Braitenberg experiment in biology lab",
    "thumbnail": "ExDBraitenbergMouseLab.jpg",
    "description": "This experiment loads the soft-skin mouse model in a biology lab environment. If the user starts the experiment, the mouse will stay still, until its eyes detect a red color on one screen. Then, the mouse will move the head towards the colored object. In this experiment, the user can interact and change the color of both screens by clicking on them with the right mouse button.",
    "tags": "mouse biological visual braitenberg biologylab",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDBraitenbergMouseLab.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDBraitenbergMouseLab.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "biologylab_world/biologylab.sdf",
      "robotPose": {
        "x": "-1.0",
        "y": "-2.0",
        "z": "1.135",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "1.58692500941"
      }
    },
    "visualModel": {
      "src": "mouse_v2_model/meshes/mouse_v2_model_animated.dae",
      "scale": "0.01",
      "visualPose": {
        "x": "-0.895",
        "y": "-1.9975",
        "z": "1.115",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "1.5708"
      }
    },
    "bibiConf": {
      "src": "braitenberg_mouse_lab.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "-1.2",
        "y": "-1.7",
        "z": "1.4"
      },
      "cameraLookAt": {
        "x": "-1.0",
        "y": "-2.0",
        "z": "1.15"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ExDConfFile.xsd",
    "name": "Dynamic Vision Sensor (DVS) simulation",
    "thumbnail": "ExDDvsRobotHead.jpg",
    "description": "This experiment contains the NST robotic head equipped with two simulated Dynamic Vision Sensors (DVS, or silicon retina).",
    "tags": "dynamic dvs vision robotics virtualroom",
    "timeout": "840",
    "configuration": [
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDDvsRobotHead.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "tracking_world/tracking_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.0",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "DVSRobotHead.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "CDP1 Mouse experiment",
    "thumbnail": "ExDMouseCDP1.jpg",
    "description": "CDP-1 mouse experiment MVP",
    "tags": "mouse biological cdp1 msled empty",
    "timeout": "1000000000",
    "configuration": [
      {
        "src": "ExDMouseCDP1.ini"
      },
      {
        "src": "MouseCDP1NeuronCoords.json"
      },
      {
        "src": "ExDMouseCDP1.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "cdp1_world/cdp1_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.0",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "0.0"
      }
    },
    "bibiConf": {
      "src": "MouseCDP1.bibi"
    },
    "experimentControl": {
      "stateMachine": {
        "type": "SMACHStateMachine",
        "id": "MouseCDP1Control_SMACH",
        "src": "MouseCDP1Control.exd"
      }
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "0.20881767737668355",
        "y": "-0.26",
        "z": "0.07452707557551946"
      },
      "cameraLookAt": {
        "x": "-0.527092211",
        "y": "0.839239426",
        "z": "-0.133607597"
      }
    },
    "physicsEngine": "opensim",
    "gzbridgesettings": {
      "pose_update_delta_translation": "1.e-12",
      "pose_update_delta_rotation": "1.e-12",
      "pose_update_early_threshold": "0.02"
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Template docked Lauron in empty environment",
    "thumbnail": "ExDTemplateDockedLauron.jpg",
    "description": "This experiment loads the Lauron robot from a docker container in an empty world, with an idle brain and basic transfer functions. You are free to edit it.",
    "tags": "lauron template docked lauron empty",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDTemplateDockedLauron.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDTemplateDockedLauron.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "empty_world/empty_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "1",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "0.0"
      }
    },
    "bibiConf": {
      "src": "docked_template_lauron.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Template Husky timeouted experiment",
    "thumbnail": "ExDTemplateHuskyTimeout.jpg",
    "description": "Test experiment for timeout testing.",
    "tags": "template husky robotics timeout",
    "timeout": "120",
    "configuration": [
      {
        "src": "ExDTemplateHuskyTimeout.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDTemplateHuskyTimeout.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "empty_world/empty_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.5",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "0.0"
      }
    },
    "bibiConf": {
      "src": "template_husky.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Holodeck Husky Braitenberg experiment with asynchronous SpiNNaker",
    "thumbnail": "ExDSpiNNakerExample.jpg",
    "description": "This is a SpiNNaker experiment that utilizes the live input/output of spikes",
    "tags": "holodeck Husky braitenberg spinnaker robotics",
    "timeout": "6000",
    "maturity": "development",
    "environmentModel": {
      "src": "virtual_room/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "1.0",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "asynchronous_spinnaker.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Holodeck iCub Visual Tracking experiment with Retina & RG opponency",
    "thumbnail": "ExDRetinaICubTrackingRG.png",
    "description": "In this experiment the iCub robot performs a Visual Tracking task in the holodeck exploiting Red-Green color opponency.",
    "tags": "holodeck icub visual tracking retina",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDRetinaICubTrackingRG.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDRetinaICubTrackingRG.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "virtual_room/virtual_room_tracking_icub.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "1.5",
        "z": "0.644",
        "roll": "0.0",
        "pitch": "0.0",
        "yaw": "-1.570796"
      }
    },
    "bibiConf": {
      "src": "visual_tracking_icub_retina_tracking_rg.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "1.4",
        "y": "2.15",
        "z": "1.0"
      },
      "cameraLookAt": {
        "x": "0.0",
        "y": "1.48",
        "z": "0.8"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "SpiNNaker MVP I",
    "thumbnail": "ExDSpiNNakerExample.jpg",
    "description": "This is an MVP of the spinnaker integration, demonstrating spike recorders and leaky integrators",
    "tags": "holodeck Husky braitenberg spinnaker robotics",
    "timeout": "6000",
    "maturity": "development",
    "environmentModel": {
      "src": "virtual_room/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "1.0",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "spinnaker_mvp_i.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Husky Braitenberg experiment with distributed brain (Nest only)",
    "thumbnail": "ExDDistributedBrainHuskyHolodeck.png",
    "description": "This experiment loads the Husky robot from Clearpath Robotics and the virtual room environment. If the user starts the experiment, the Braitenberg vehicle network is executed and the robot will turn around itself in place, until the camera detects a red color. Then, the robot will move towards the colored object. In this experiment, the user can interact and change the color of both screens by clicking on them with the right mouse button.",
    "tags": "husky robotics distributed braitenberg nest holodeck",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDXMLExample.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDXMLExample.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "virtual_room/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.5",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "milestone2_python_tf.bibi",
      "processes": "2"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ExDConfFile.xsd",
    "name": "Multiple robots tutorial",
    "thumbnail": "MultipleRobots.jpg",
    "description": "This experiment contains one iCub robot and two Pioneer 3DX equipped with brain models.",
    "tags": "multiple robots tutorial",
    "timeout": "1800",
    "configuration": [
      {
        "src": "MultipleRobots.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "MultipleRobots.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "multi_robots_environment/multi_robots_environment.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "-0.5",
        "z": "0.63",
        "roll": "0.0",
        "pitch": "0.0",
        "yaw": "-1.57079632679"
      }
    },
    "bibiConf": {
      "src": "MultipleRobots.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "2.5",
        "y": "2.5",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    },
    "rosLaunch": {
      "src": "robot_description.launch"
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "HoLLiE hand motion with CPG",
    "thumbnail": "ExDManipulation.jpg",
    "description": "This experiment shows a basic implementation of CPG driven motion control for a five-finger robotic hand. The transfer functions implement a simple muscle model.",
    "tags": "virtualroom robotics hollie hand finger cpg",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDManipulation.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDManipulation.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "virtual_room_lausanne/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.025",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "manipulation.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "-1.05711",
        "y": "2.06968",
        "z": "2.08684"
      },
      "cameraLookAt": {
        "x": "0.0",
        "y": "0.231642",
        "z": "1.199802"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "CDP4 attention model",
    "thumbnail": "cdp4.png",
    "description": "Saliency model from Maastricht in closed-loop.",
    "timeout": "86400",
    "configuration": {
      "src": "cdp4.3ds"
    },
    "maturity": "production",
    "environmentModel": {
      "src": "CDP4_Models/world_fifteen_posters.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "-1.0",
        "z": "0.0",
        "ux": "0.0",
        "uy": "0.0",
        "uz": "1.0",
        "theta": "0.0"
      }
    },
    "bibiConf": {
      "src": "cdp4.bibi"
    },
    "experimentControl": {
      "stateMachine": [
        {
          "type": "SMACHStateMachine",
          "id": "SaccadeCharacteristics",
          "src": "sm/saccade_characteristics_machine.exd"
        },
        {
          "type": "SMACHStateMachine",
          "id": "ChangePosters",
          "src": "sm/change_posters_machine.exd"
        }
      ]
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "3.25",
        "y": "4.75",
        "z": "4.25"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.5"
      }
    },
    "rosLaunch": {
      "src": "nrp.launch"
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "CDP4 attention model",
    "thumbnail": "cdp4.png",
    "description": "Saliency model from Maastricht in closed-loop.",
    "timeout": "86400",
    "configuration": {
      "src": "cdp4.3ds"
    },
    "maturity": "production",
    "environmentModel": {
      "src": "CDP4_models/world_indoor.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "-1.0",
        "z": "0.0",
        "ux": "0.0",
        "uy": "0.0",
        "uz": "1.0",
        "theta": "0.0"
      }
    },
    "bibiConf": {
      "src": "cdp4.bibi"
    },
    "experimentControl": {
      "stateMachine": [
        {
          "type": "SMACHStateMachine",
          "id": "SaccadeCharacteristics",
          "src": "sm/saccade_characteristics_machine.exd"
        },
        {
          "type": "SMACHStateMachine",
          "id": "ChangePosters",
          "src": "sm/change_posters_machine.exd"
        }
      ]
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "3.25",
        "y": "4.75",
        "z": "4.25"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.5"
      }
    },
    "rosLaunch": {
      "src": "nrp.launch"
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Benchmark Pioneer P3DX experiment",
    "thumbnail": "BenchmarkPioneer.jpg",
    "description": "Benchmark aiming at developing a program that controls a Pioneer 3DX robot to follow a 2m by 2m square path. The metric used to evaluate the robot is applied for 4 separate segments of the path, which correspond to the 4 sides of the square. The final performance is computed averaging the 4 segments evaluations. Each segment is defined as a corridor that lies on one edge of the square. For each individual segment, we compute a performance which is based on 3 different parameters: the \"path\" (how well the robot managed to keep close to the \"ideal\" route), the \"time\" needed to go through this segment, and the \"distance\" to the goal, which is mostly used to evaluate how close to the goal the robot is in the current segment.",
    "tags": "benchmark pioneer woodcheckerboard trajectory robotics",
    "timeout": "840",
    "configuration": [
      {
        "src": "BenchmarkPioneer.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "BenchmarkPioneer.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "p3dxbenchmark_world/p3dxbenchmark_world.sdf",
      "robotPose": {
        "x": "-1.0",
        "y": "1.0",
        "z": "0.05",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "0.0"
      }
    },
    "bibiConf": {
      "src": "template_pioneer.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "1.8384600722731907",
        "y": "-1.6578606691120366",
        "z": "1.4069850686414418"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.5"
      }
    },
    "rosLaunch": {
      "src": "robot_description.launch"
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ExDConfFile.xsd",
    "name": "Husky Braitenberg experiment with zipped robot",
    "thumbnail": "ExDXMLExampleRobotZip.jpg",
    "description": "This experiment loads the Husky robot from Clearpath Robotics from a zip file and the virtual room environment. If the user starts the experiment, the Braitenberg vehicle network is executed and the robot will turn around itself in place, until the camera detects a red color. Then, the robot will move towards the colored object. In this experiment, the user can interact and change the color of both screens by clicking on them with the right mouse button.",
    "tags": "husky braitenberg robotics zipped virtualroom",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDXMLExample.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDXMLExample.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "virtual_room/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.5",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "milestone2_python_tf_robotzip.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "NAO experiment",
    "thumbnail": "ExDNao.jpg",
    "description": "This experiment loads the humanoid robot NAO (Aldebaran) and the virtual room environment. In the future, it will be possible to connect NAO to a neuronal controller (NEST) to control single joints of the robot.",
    "tags": "nao humanoid virtualroom robotics",
    "timeout": "840",
    "configuration": {
      "src": "brainvisualizer.json"
    },
    "environmentModel": {
      "src": "virtual_room/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "-0.157",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "nao.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Husky Braitenberg experiment with automatically switching screens",
    "thumbnail": "ScreenSwitchingHuskyExperiment.jpg",
    "description": "This experiment is similar to the Husky Braitenberg one (Husky robot detecting red colour and driving towards it). In this experiment the right screen is turned red automatically after 20 seconds of simulation time. Also, the robot reaching a red screen triggers on the opposite screen. This is to demonstrate how, using the SMACH state machine script, the user can automate the experiment events.",
    "tags": "husky robotics braitenberg virtualroom",
    "timeout": "840",
    "configuration": [
      {
        "src": "ScreenSwitchingHuskyExperiment.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ScreenSwitchingHuskyExperiment.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "virtual_room_lausanne/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.5",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "milestone2.bibi"
    },
    "experimentControl": {
      "stateMachine": {
        "type": "SMACHStateMachine",
        "id": "HuskyAwareScreenControlling",
        "src": "screen_switching_husky_aware_compatible.exd"
      }
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "2.1504202465717563",
        "y": "1.2381462778435453",
        "z": "1.3380507195673994"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.49999"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Husky Braitenberg experiment on SpiNNaker",
    "thumbnail": "ExDXMLExample.jpg",
    "description": "This experiment loads the Husky robot from Clearpath Robotics and the virtual room environment. If the user starts the experiment, the Braitenberg vehicle network is executed and the robot will turn around itself in place, until the camera detects a red color. Then, the robot will move towards the colored object. In this experiment, the user can interact and change the color of both screens by clicking on them with the right mouse button. The neural network used in this experiment is SpiNNaker.",
    "tags": "husky braitenberg robotics spinnaker virtualroom neuromorphics",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDXMLExample.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDXMLExample.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "virtual_room_lausanne/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.5",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "spinnaker_husky_braitenberg.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "2.1504202465717563",
        "y": "1.2381462778435453",
        "z": "1.3380507195673994"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.49999"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Husky Braitenberg experiment with distributed brain (Nest with MUSIC)",
    "thumbnail": "ExDDistributedBrainHuskyMUSICHolodeck.png",
    "description": "WARNING: This experiment has limited functionality, use at your own risk! See the corresponding Nest only experiment for a distributed, more feature complete version.",
    "tags": "husky robotics distributed braitenberg music",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDXMLExample.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDXMLExample.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "virtual_room/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.5",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "milestone2_python_tf.bibi",
      "processes": "2"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Holodeck Interactive manipulation experiment",
    "thumbnail": "ExDManipulation.jpg",
    "description": "This experiment allows user to control Schunk robotic manipulator (arm and hand) using Myo armband and Leap Motion hand tracker using client side ROS nodes in the Holodeck.",
    "tags": "holodeck nteractive robotics hollie hand finger",
    "timeout": "840",
    "configuration": [
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDInteractiveManipulation.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "virtual_room/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.025",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "interactive_manipulation.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "-1.05711",
        "y": "2.06968",
        "z": "2.08684"
      },
      "cameraLookAt": {
        "x": "0.0",
        "y": "0.231642",
        "z": "1.199802"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Force based joint control",
    "thumbnail": "ExDManipulationForce.jpg",
    "description": "The experiment shows a simple example of force based spiking interface for a Schunk SVH robotic hand. Two joints of the index finger are being controlled by two motor neurons (antagonist and synergist) to reach a desired position, which is adjustable in the transfer function. A simple muscle model converts activation dynamics to joint efforts and applies them in a physics simulator. The rest of the 8 joints (2 for each finger) are maintaining zero positions with traditional PID controllers and do not move at all. The experiment demonstrates one of the possible mechanisms for implementing force based control using existing Gazebo/ROS NRP platform architecture, opening the path to more complex muscle model simulations in the future.",
    "tags": "virtualroom robotics schunk hand finger force joint",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDManipulationForce.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDManipulationForce.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "virtual_room_lausanne/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.025",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "manipulation_force.bibi"
    },
    "experimentControl": {
      "stateMachine": {
        "type": "SMACHStateMachine",
        "id": "IndexFingerForceControl",
        "src": "manipulation_arm_robot_force.exd"
      }
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "-1.05711",
        "y": "2.06968",
        "z": "2.08684"
      },
      "cameraLookAt": {
        "x": "0.0",
        "y": "0.231642",
        "z": "1.199802"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Empty Template Mouse v2 experiment",
    "thumbnail": "ExDTemplateMouseV2.jpg",
    "description": "This experiment loads the Mouse in an empty world, with an idle brain and basic transfer functions, as well as a prototype docked robot controller. You are free to edit it.",
    "tags": "empty template mouse docked biological",
    "timeout": "840",
    "configuration": {
      "src": "brainvisualizer.json"
    },
    "maturity": "development",
    "environmentModel": {
      "src": "empty_world/empty_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.1",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "2.29524196972"
      }
    },
    "bibiConf": {
      "src": "template_mousev2.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Holodeck CDP1 Mouse experiment",
    "thumbnail": "ExDMouseCDP1.jpg",
    "description": "CDP-1 mouse experiment MVP",
    "tags": "mouse biological cdp1 holodeck",
    "timeout": "1000000000",
    "configuration": [
      {
        "src": "holodeck.ini"
      },
      {
        "src": "MouseCDP1NeuronCoords.json"
      },
      {
        "src": "holodeck.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "cdp1_world/cdp1_world_holodeck.sdf",
      "robotPose": {
        "x": "1.51587",
        "y": "-1.0442",
        "z": "1.3375",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "0.0"
      }
    },
    "bibiConf": {
      "src": "MouseCDP1.bibi"
    },
    "experimentControl": {
      "stateMachine": {
        "type": "SMACHStateMachine",
        "id": "MouseCDP1Control_SMACH",
        "src": "MouseCDP1Control.exd"
      }
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "1.650596943953666",
        "y": "-1.3037450422457924",
        "z": "1.3963657402299325"
      },
      "cameraLookAt": {
        "x": "1.51587",
        "y": "-1.0442",
        "z": "1.33757"
      }
    },
    "physicsEngine": "opensim",
    "gzbridgesettings": {
      "pose_update_delta_translation": "1.e-12",
      "pose_update_delta_rotation": "1.e-12",
      "pose_update_early_threshold": "0.02"
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Husky Braitenberg experiment",
    "thumbnail": "ExDXMLExample.jpg",
    "description": "This experiment loads the Husky robot from Clearpath Robotics and the virtual room environment. If the user starts the experiment, the Braitenberg vehicle network is executed and the robot will turn around itself in place, until the camera detects a red color. Then, the robot will move towards the colored object. In this experiment, the user can interact and change the color of both screens by clicking on them with the right mouse button.",
    "tags": "husky robotics braitenberg virtualroom",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDXMLExample.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDXMLExample.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "virtual_room_lausanne/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.5",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "milestone2_python_tf.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "2.1504202465717563",
        "y": "1.2381462778435453",
        "z": "1.3380507195673994"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.49999"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "HoLLie arm manipulation demo experiment",
    "thumbnail": "ExDDemoManipulation.jpg",
    "description": "The experiment shows the HoLLie arm performing an infinite grasping task controlled by a SMACH state machine. The robot clears the table of the two cylindrical objects placed on it, disposing of them in the container beside.",
    "tags": "hollie arm manipulation demo empty robotics",
    "timeout": "180",
    "configuration": [
      {
        "src": "ExDDemoManipulation.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDDemoManipulation.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "empty_world/world_manipulation.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.04",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "manipulation_demo.bibi"
    },
    "experimentControl": {
      "stateMachine": {
        "type": "SMACHStateMachine",
        "id": "ArmBehavior",
        "src": "manipulation_demo.exd"
      }
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "0.84782",
        "y": "-2.38183",
        "z": "2.4"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "1"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "SpiNNaker MVP II",
    "thumbnail": "ExDSpiNNakerExample.jpg",
    "description": "This is an MVP of the spinnaker integration, demonstrating spike recorders and spike injectors",
    "tags": "holodeck Husky braitenberg spinnaker robotics",
    "timeout": "6000",
    "maturity": "development",
    "environmentModel": {
      "src": "virtual_room/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "1.0",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "spinnaker_mvp_ii.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Roboy experiment",
    "thumbnail": "roboy.jpg",
    "description": "This experiment loads the anthropomimetic robot Roboy into the SpaceBotCup Arena. In the future, muscle simulations will be added which then can be controlled by a neural network (NEST).",
    "tags": "roboy robotics spacebotcup",
    "timeout": "840",
    "configuration": {
      "src": "brainvisualizer.json"
    },
    "environmentModel": {
      "src": "spacebotcup_world/spacebotcup_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "-0.157",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "roboy.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "iCub VOR UGR",
    "thumbnail": "ExDiCub_VOR_UGR.png",
    "description": "This experiment of the University of Granada (UGR) is a VOR experiment using a spiking cerebellar model and an iCub robot.",
    "tags": "icub robotics visual holodeck",
    "timeout": "86400",
    "configuration": {
      "src": "ExDiCub_VOR_UGR.3ds"
    },
    "maturity": "production",
    "environmentModel": {
      "src": "virtual_room_lausanne/vor_environment.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.644",
        "ux": "0.0",
        "uy": "0.0",
        "uz": "-0.70710666564709435",
        "theta": "0.70710689672598181"
      }
    },
    "bibiConf": {
      "src": "bibi_configuration.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "2.1504202465717563",
        "y": "1.2381462778435453",
        "z": "1.3380507195673994"
      },
      "cameraLookAt": {
        "x": "0.0",
        "y": "1.48",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "LAURON V Braitenberg experiment",
    "thumbnail": "ExDBraitenbergLauron.jpg",
    "description": "This experiment loads the six-legged walking robot LAURON V (developed at FZI) and the virtual room environment. If the user starts the experiment, the Braitenberg vehicle network is executed and the robot will turn around itself in place, until the camera detects a red color. Then, the robot will move towards the colored object. In this experiment, the user can interact and change the color of both screens by clicking on them with the right mouse button.",
    "tags": "lauron robotics virtualroom braitenberg",
    "timeout": "840",
    "configuration": [
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDBraitenbergLauron.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "virtual_room/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.0",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "3.14159265359"
      }
    },
    "bibiConf": {
      "src": "braitenberg_lauron.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Husky Braitenberg experiment in the SpaceBotCup 2013 arena",
    "thumbnail": "ExDBraitenbergHuskySBC.jpg",
    "description": "This experiment loads the Husky robot from Clearpath Robotics and the arena from the SpaceBotCup 2013. If the user starts the experiment, the Braitenberg vehicle network is executed and the robot will turn around itself in place, until the camera detects a red color. Then, the robot will move towards the colored object. In this experiment, the user can interact and change the color of both screens by clicking on them with the right mouse button.",
    "tags": "husky robotics spacebotcup braitenberg",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDBraitenbergHuskySBC.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDBraitenbergHuskySBC.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "spacebotcup_world/spacebotcup_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "1.0",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "0.0"
      }
    },
    "bibiConf": {
      "src": "milestone2.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "-2.0234778231193573",
        "y": "1.2958129048076932",
        "z": "2.083016416394317"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "1.24999"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ExDConfFile.xsd",
    "name": "Holodeck Mouse Braitenberg experiment",
    "thumbnail": "ExDBraitenbergMouseLab.jpg",
    "description": "This experiment loads the soft-skin mouse model in the holodeck biolab environment. If the user starts the experiment, the mouse will stay still, until its eyes detect a red color on one screen. Then, the mouse will move the head towards the colored object. In this experiment, the user can interact and change the color of both screens by clicking on them with the right mouse button.",
    "tags": "mouse biological visual holodeck braitenberg",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDBraitenbergMouseLab.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDBraitenbergMouseLab.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "holodeck_biolab/holodeck_biolab.sdf",
      "robotPose": {
        "x": "1.659",
        "y": "-0.851",
        "z": "1.319",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "1.58692500941"
      }
    },
    "visualModel": {
      "src": "mouse_v2_model/meshes/mouse_v2_model_animated.dae",
      "scale": "0.01",
      "visualPose": {
        "x": "1.715",
        "y": "-0.851",
        "z": "1.319",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "1.5708"
      }
    },
    "bibiConf": {
      "src": "braitenberg_mouse_lab.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "1.1421603714651787",
        "y": "-1.015793401143827",
        "z": "1.7139510542349161"
      },
      "cameraLookAt": {
        "x": "1.659",
        "y": "-0.851",
        "z": "1.319"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Tigrillo Learning Experiment",
    "thumbnail": "ExDTigrillo.png",
    "description": "In this experiment, the quadruped robot Tigrillo uses a target actuation signal optimized previously with CMA-ES to learn how to use proprioceptive knee sensors in a closed loop system. This controller is made of a Liquid State Machine whose outputs are learned with the FORCE update rule and progressively mixed to the target signal until it walks fully in closed-loop.",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDTigrillo.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDTigrillo.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "empty_virtuallab/empty_virtuallab.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.5",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "0.0"
      }
    },
    "bibiConf": {
      "src": "ExDTigrillo.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "The Real Tigrillo Experiment",
    "thumbnail": "ExDTigrillo.png",
    "description": "Controlling the real Tigrillo Robot with the NRP.",
    "timeout": "840",
    "configuration": {
      "src": "TigrilloReal.ini"
    },
    "maturity": "development",
    "environmentModel": {
      "src": "virtual_room/virtual_room.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.0",
        "roll": "0.0",
        "pitch": "0.0",
        "yaw": "0.0"
      }
    },
    "bibiConf": {
      "src": "TigrilloReal.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "2.1504202465717563",
        "y": "1.2381462778435453",
        "z": "1.3380507195673994"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.49999"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "User Avatar - Test Environment",
    "thumbnail": "user-avatar-thumbnail.jpg",
    "description": "This is a test environment for implementations of user avatars.",
    "tags": "avatar user test",
    "timeout": "9999",
    "configuration": [
      {
        "src": "user-avatar_test-env.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "user-avatar_test-env.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "empty_virtuallab/empty_virtuallab.sdf",
      "robotPose": {
        "x": "1.929",
        "y": "0.286",
        "z": "0.949",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "2.29524196972"
      }
    },
    "bibiConf": {
      "src": "user-avatar_test-env.bibi"
    },
    "experimentControl": {
      "stateMachine": {
        "type": "SMACHStateMachine",
        "id": "AvatarTests",
        "src": "avatar_tests.exd"
      }
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "Template Pioneer P3DX in empty environment",
    "thumbnail": "ExDTemplatePioneer.jpg",
    "description": "This experiment loads the Pioneer P3DX robot in an empty world, with an idle brain and basic transfer functions. You are free to edit it.",
    "tags": "pioneer robotics template empty",
    "timeout": "840",
    "configuration": [
      {
        "src": "ExDTemplatePioneer.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "ExDTemplatePioneer.uis"
      }
    ],
    "maturity": "production",
    "environmentModel": {
      "src": "empty_world/empty_world.sdf",
      "robotPose": {
        "x": "0.0",
        "y": "0.0",
        "z": "0.5",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "0.0"
      }
    },
    "bibiConf": {
      "src": "template_pioneer.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "4.5",
        "y": "0",
        "z": "1.8"
      },
      "cameraLookAt": {
        "x": "0",
        "y": "0",
        "z": "0.6"
      }
    },
    "rosLaunch": {
      "src": "robot_description.launch"
    }
  },
  {
    "schemaLocation": "http://schemas.humanbrainproject.eu/SP10/2014/ExDConfig ../ExDConfFile.xsd",
    "name": "1 DOF Myorobotics Arm for WP4 Cerebellum Experiment",
    "thumbnail": "Myo_small.jpg",
    "description": "Loads the 1 DOF Myorobotics Arm into the Holodeck. Muscles can be controlled via ROS messages.",
    "timeout": "1000000000",
    "configuration": [
      {
        "src": "holodeck.ini"
      },
      {
        "src": "brainvisualizer.json"
      },
      {
        "src": "holodeck.uis"
      }
    ],
    "maturity": "development",
    "environmentModel": {
      "src": "cdp1_world/cdp1_world_holodeck.sdf",
      "robotPose": {
        "x": "-1",
        "y": "-4.0",
        "z": "0.1",
        "roll": "0.0",
        "pitch": "-0.0",
        "yaw": "0.0"
      }
    },
    "bibiConf": {
      "src": "Myo_small.bibi"
    },
    "cameraPose": {
      "cameraPosition": {
        "x": "1.650596943953666",
        "y": "-1.3037450422457924",
        "z": "1.563657402299325"
      },
      "cameraLookAt": {
        "x": "1.51587",
        "y": "-1.0442",
        "z": "1.33757"
      }
    },
    "physicsEngine": "opensim",
    "gzbridgesettings": {
      "pose_update_delta_translation": "1.e-12",
      "pose_update_delta_rotation": "1.e-12",
      "pose_update_early_threshold": "0.02"
    }
  }
]
